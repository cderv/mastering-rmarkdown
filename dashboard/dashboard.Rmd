---
title: "Dashboard for SO questions in Rmarkdown Cookbook"
output: 
  flexdashboard::flex_dashboard:
    self_contained: false
    orientation: rows
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(polite)
library(rvest)
library(purrr)
# control what evaluate or not in dev mode
is_dev <- as.logical(Sys.getenv("IS_DEV", FALSE))
message(ifelse(is_dev, "DEV MODE ON", "DEV MODE OFF")) 
```

```{r parsing-so, eval = FALSE}
# Get Top 500 SO questions
## scrape website
# we want to retrieve the 500 top question
so_url <- "https://stackoverflow.com/questions/tagged/r-markdown"
session <- bow(so_url)
top <- 500
result_per_page <- 50
nb_page <- ceiling(top / 50)
# nb_page <- 1
res <- seq_len(nb_page) %>%
  map(~ scrape(session, 
               params =
                 glue::glue(
                   "page={page_nb}&sort=votes&pagesize={result_per_page}", 
                   page_nb = .x), 
               verbose = TRUE
  ))
```

```{r get-so-qa-url, eval = FALSE}
## get question url
so_top_qa <- res %>%
  map(~html_nodes(.x, "h3 >a.question-hyperlink") %>%
        html_attr("href") %>%
        map_chr(~ httr::modify_url(so_url, path = .x))) %>%
  flatten_chr() %>%
  tibble(urls = .) %>%
  mutate(
    top = row_number(),
    id = str_extract(urls, "(?<=/)\\d{8}(?=/)") 
  )
readr::write_csv(so_top_qa, "TOP500_QA_SO.csv")
```

```{r parsing-most-viewed}
# Exported from 
# https://data.stackexchange.com/stackoverflow/query/341524/most-viewed-questions-in-tag#resultSets
# on 13/04/2020
most_viewed <- read_csv("MOST_VIEWED_QA_SO.csv", 
    col_types = cols(`Post Link` = col_character())) %>%
  arrange(desc(ViewCount)) %>%
  rename(id = `Post Link`) %>%
  mutate(most_viewed = row_number())
```

```{r get-so-in-gh, eval = TRUE}
# helpers
get_so_id <- function(so_url) {
  str_extract(so_url, "(?<=questions/)\\d{8}(?=/.*)")
}
get_ke_example <- function(ke_url) {
  example <- str_extract(ke_url, "(?<=knitr-examples/blob/master/)\\d{3}.*(?=\\.[:alpha:])")
  list(id = str_extract(example, "^\\d{3}") %>% as.numeric(),
       name = str_extract(example, "(?<=\\d{3}-).*")
  )
}

# REM : NOT RUN IN DEV MODE (if IS_DEV env var is true)
# Find QA already looked at on GH
# Use github graphQL API
if (!is_dev){
  # remotes::install_github("ropenscilabs/ghrecipes")
  library(ghrecipes)
  owner <- "yihui"
  repo <- "rmarkdown-cookbook"
  ignored_issues <- c(4)
  issues <- get_issue_labels_state(owner, repo)
  get_all_thread <- map_dfr(issues$number, ~ get_issue_thread(owner, repo, .x))
  saveRDS(get_all_thread, "get_all_threads.Rds")
  so_in_gh <- get_all_thread %>%
    # do not select some issue
    filter(!issue %in% ignored_issues) %>%
    # get only issues with stackoverflow url
    mutate(has_so_url = str_detect(body, "https://stackoverflow.com")) %>%
    filter(has_so_url) %>%
    mutate(so_url = str_extract_all(body, "\\bhttps://stackoverflow.com/[^\\s)]*")) %>%
    unnest(so_url) %>%
    # deal with comment shared url
    mutate(so_url = map_if(so_url, 
                           ~str_detect(.x, "https://stackoverflow.com/a/.*"), 
                           ~httr::GET(.x)$url) %>% flatten_chr,
           id = get_so_id(so_url)) %>%
    # Add status
    mutate(status = if_else(grepl("^9999-01-01$", closed_at), "OPENED", "CLOSED")) %>%
    select(issue, status, so_url_gh = so_url, id) %>%
    distinct()
  # get knitr example
  knit_example_in_gh <- get_all_thread %>%
    filter(!issue %in% ignored_issues) %>%
    # get only issues with stackoverflow url
    mutate(has_ke_url = str_detect(body, "https://github.com/yihui/knitr-examples[/]?[^\\s)\\.]")) %>%
    filter(has_ke_url) %>%
    mutate(ke_url = str_extract_all(body, "\\bhttps://github.com/yihui/knitr-examples[^\\s)]*")) %>%
    unnest(ke_url) %>%
    mutate(example = map(ke_url, get_ke_example),
           id = map_dbl(example, "id"),
           name = map_chr(example, "name"),
           status = if_else(grepl("^9999-01-01$", closed_at), "OPENED", "CLOSED")) %>%
    select(issue, status, id, name, ke_url, comment_url)
  # saved once for dev purposes
  saveRDS(so_in_gh, "so_in_gh.rds")
  saveRDS(knit_example_in_gh, "knit_example_in_gh.rds")
}
```
  
```{r load-dev-table, eval = TRUE}
# only run if IS_DEV env var is TRUE
# Purpose : Prevent github api request in dev mode
if (is_dev) {
  so_in_gh <- readRDS("so_in_gh.rds")
  knit_example_in_gh <- readRDS("knit_example_in_gh.rds")
}
```


```{r data-top-500-in-gh}
# summary of already dealt issues
top_QA <- read_csv("TOP500_QA_SO.csv", col_types = "cic")
ignored_qa <- gistr::gist("https://gist.github.com/cderv/76728b02c13e429c843cc8b3b7226f11") %>%
  purrr::pluck("files", "ignored_qa.txt", "raw_url") %>%
  readr::read_tsv(col_names = "so_url", col_types = "c") %>%
  dplyr::mutate(id = get_so_id(so_url))
full_table <- so_in_gh %>%
  # add top QA
  full_join(top_QA, by = "id") %>%
  # add most viewed already Top QA
  left_join(most_viewed %>% select(id, ViewCount, most_viewed), by = "id") %>%
  # add most 500 viewed not already in
  full_join(most_viewed %>% select(id, ViewCount, most_viewed) %>% filter(most_viewed <= 500)) %>%
  select(top, urls, id, issue, status, most_viewed, ViewCount) %>%
  arrange(top, most_viewed) %>%
  mutate(
    # build url for SO questions not in the top 500
    urls = if_else(is.na(urls), paste0("https://stackoverflow.com/questions/", id), urls),
    # create link
    urls = map_chr(urls, ~htmltools::a(.x, href = .x, target="_blank") %>% as.character),
    # create link toward issue
    issue_link = map_chr(
      issue, 
      ~htmltools::a(.x,
                    href = paste0("https://github.com/yihui/rmarkdown-cookbook/issues/", .x),
                    target="_blank") %>%
        as.character()),
    ignored = id %in% ignored_qa$id 
  )
```


Dashboard
===========================

Updated: `r Sys.time()`

Row
----------------------------------------

### Nb of questions in closed GH ticket

```{r}
closed_rate <- full_table %>% 
  filter(!is.na(issue)) %>% 
  distinct(id, .keep_all = TRUE) %>%
  group_by(id) %>% 
  summarise(CLOSED = all(status == "CLOSED")) %>% 
  count(CLOSED)
flexdashboard::gauge(closed_rate %>% filter(CLOSED == TRUE) %>% pull(n),
                     0, 
                     sum(closed_rate$n))
```

```{r, include = FALSE}
summary_qa <- function(full_table, type) {
  type <- enquo(type)
  full_table %>% 
    distinct(id, .keep_all = TRUE) %>%
    filter(!is.na(!!type)) %>%
    mutate(cat = case_when(
      !is.na(issue) ~ "in_gh",
      ignored       ~ "ignored",
      TRUE          ~ "not reported"
    )) %>%
    count(cat)
}

achievement_gauge <- function(full_table, type) {
  type <- enquo(type)
  tab <- full_table %>%
    summary_qa(!!type) %>%
    mutate(ok = !cat == "not reported") %>%
    group_by(ok) %>%
    summarise(n = sum(n))
  flexdashboard::gauge(tab %>% filter(ok) %>% pull(n), min = 0, max = sum(tab$n))
}

vb_custom <- function(full_table, type, category, caption = "", color = "blue") {
  type <- enquo(type)
  full_table %>% 
    summary_qa(!!type) %>% 
    filter(cat == category) %>%
    pull(n) %>%
    flexdashboard::valueBox(caption = caption, color = color)
}

vb_in_gh <- function(full_table, type, caption = "") {
  type <- enquo(type)
  vb_custom(full_table, !!type, "in_gh", caption, "green")
}

vb_ignored <- function(full_table, type, caption = "") {
  type <- enquo(type)
  vb_custom(full_table, !!type, "ignored", caption, "darkgrey")
}
```

### Number of QA reported in GH

```{r total-in-gh}
full_table %>% 
  filter(!is.na(issue)) %>%
  distinct(id) %>%
  count() %>%
  pull(n) %>%
  flexdashboard::valueBox(caption = "QA in total in GH", color = "MediumSeaGreen")
```

### Number of knitr example reported in GH

```{r nb-knitr-ex}
knit_example_in_gh %>% 
  distinct(id) %>%
  count() %>%
  pull(n) %>%
  flexdashboard::valueBox(caption = "Number of knitr examples reported in GH", color = "purple")
```

Row
-------------

### Achievement on the top 500

```{r achievement-gauge}
achievement_gauge(full_table, top)
```

### Achievement on MOST VIEWED

```{r achievement-gauge-most-viewed}
achievement_gauge(full_table, most_viewed)
```



Row
----------------------------

### Nb of SO questions reported not in either Tops

```{r all-so}
flexdashboard::valueBox(
  full_table %>% filter(is.na(top) & is.na(most_viewed)) %>% count() %>% pull(n),
  caption = "Number of SO QA not in TOP or most viewed"
)
```

### Nb of ignored questions

```{r ignored-so}
flexdashboard::valueBox(
  nrow(ignored_qa),
  caption = "Number of ignored SO QA, not reported in GH"
)
```

Row
---------------------------

### Nb of top 500 reported in GH

```{r top-in-gh}
vb_in_gh(full_table, top, "Nb of top 500 reported in GH")
```

### Nb of most viewed reported in GH

```{r most_viewed-in-gh}
vb_in_gh(full_table, most_viewed, "Nb of most viewed reported in GH")
```

### Nb of top 500 ignored

```{r top-ignored}
vb_ignored(full_table, top, "Nb of top 500 ignored")
```

### Nb of most_viewed ignored

```{r most-viewed-ignored}
vb_ignored(full_table, top, "Nb of most viewed ignored")
```

Next questions 
============================

Row
---------------------------

### Next Questions

```{r next-questions}
full_table %>%
  filter(is.na(issue) & !ignored) %>%
  select(top, most_viewed, urls) %>%
  arrange(pmin(top, most_viewed)) %>%
  DT::datatable(escape = FALSE)
```

### SO QA in GH

```{r barplot-done}
full_table %>%
  distinct(id, .keep_all = TRUE) %>%
  mutate(not_in_gh = if_else(is.na(issue), "not in GH yet", "Already in GH")) %>%
  ggplot(aes(not_in_gh, fill = not_in_gh)) +
  geom_bar(position = "dodge") +
  geom_text(aes(label = stat(count), y = stat(count)), stat = "count", vjust = -0.5, hjust = 0.5) +
  theme_light() +
  scale_x_discrete(breaks = NULL) +
  labs(
    title = "Nb of SO questions in GH issues",
    x = NULL,
    fill = "Top SO QA"
  )
```


Data 
============================

Row {.tabset .tabset-fade}
-------------------------------------------

```{r dt-wrapper, include = FALSE}
data_table <- function(tab, ...) {
  DT::datatable(tab,
                escape = FALSE, 
                filter = "top")
}
```


### All SO questions mentionned in GH issues 

This table contains QA from SO and where they are mentionned in issues

```{r render-full-table}
data_table(full_table %>% 
             filter(!is.na(issue)) %>%
             select(-issue) %>%
             # put top = 0 for non top 500 SO QA
             mutate(top = if_else(is.na(top), 0L, top),
                    most_viewed = if_else(is.na(most_viewed), 0L, most_viewed)) %>%
             filter(!ignored),
           options = list(
             columnDefs = list(list(className = 'dt-center', targets = 0:4))
           ))
```

### Ignored SO QA

```{r ignored_qa}
data_table(full_table %>%
                semi_join(ignored_qa, by = "id") %>%
                select(top, urls, id), 
)
```

### Knitr Examples

```{r knitr_ex_data}
data_table(knit_example_in_gh %>%
             mutate(
               urls = map_chr(ke_url, 
                              ~ htmltools::a(.x, href = .x, target="_blank") %>% as.character),
               issue_url = map_chr(comment_url, 
                                   ~ htmltools::a(.x, href = .x, target="_blank") %>% as.character),
             ) %>%
             select(id, name, urls, issue_url) %>%
             arrange(id)
)
```

Thank you
============================

```{r, include = FALSE}
get_user_name <- function(user) {
  # setup token
  token <- Sys.getenv("GITHUB_GRAPHQL_TOKEN", 
                      Sys.getenv("GITHUB_PAT", NA_character_))
  if (is.na(token)) stop("Setup a token for the GraphQL API in env vars")
  # connect to API V4
  con <- ghql::GraphqlClient$new(
    url = "https://api.github.com/graphql",
    headers = list(Authorization = paste0("Bearer ", token))
  )
  # con$load_schema()
  # query to get username
  qry <- ghql::Query$new()
  qry$query("username", 
            'query username($user: String!){
            user(login: $user) {
            name
            }
            }')
  res <- con$exec(qry$queries$username, variables = list(user = user))
  # parse result
  name <- jsonlite::fromJSON(
    jqr::jq(res, ".data.user.name")
  )
  if (is.null(name)) return("")
  name
}
get_user_name_mem <- memoise::memoise(get_user_name)
```


```{r}
get_all_thread <- readRDS("get_all_threads.Rds")
other_authors <- get_all_thread %>%
  # we keep only infos that are useful for author analysis
  select(author, title, issue, comment_url) %>%
  # we want other authors than us
  filter(!author %in% c("yihui", "cderv")) %>%
  # we identify comment contribution from issue creation
  mutate(
    comment = grepl("#issuecomment", comment_url),
    issue_url = gsub("#issuecomment.*$", "", comment_url),
    comment_url = NULL
    ) %>%
  # we keep only one entry by issue
  group_by(author, title, issue, issue_url) %>%
  group_modify(~ {
    .x %>% arrange(comment) %>% slice(1) %>% select(comment_only = comment)
  }) %>%
  ungroup() %>%
  mutate(author_name = purrr::map_chr(author, get_user_name_mem)) %>%
  # manually fill empty name I know
  mutate(author_name = case_when(
    author == "atusy" ~ "Atsushi Yasumoto",
    TRUE ~ author_name
  )) %>%
  select(author_name, everything()) 
saveRDS(other_authors, "other_authors.Rds")
```

Row {.tabset}
-------------------------------------------

```{r}
make_link <- function(issue, issue_url) {
  map2(issue, issue_url, ~ {
    htmltools::a(.x, href = .y, target="_blank")
  })
}
```

### Thank you for opening issues

Thank you to the user who suggested some ideas by opening an issue in the rmarkdown-cookbook repository

```{r, results='asis'}
other_authors %>%
  filter(!comment_only) %>%
  select(-comment_only) %>%
  group_by(author, author_name) %>%
  tidyr::nest() %>%
  purrr::pmap(function(author, author_name, data) {
      htmltools::tags$li(
        author_name, " (",
        make_link(
          glue::glue("@{author}"),
          glue::glue("https://github.com/{author}")
        ),"): ",
        make_link(paste0("#", data$issue), data$issue_url)
      )
  }) %>%
  htmltools::tags$ul()
```

### Thank you for participating in issues threads

Thank you to the user who share their feedback by commenting on threads in the rmarkdown-cookbook repository

```{r, results='asis'}
other_authors %>%
  filter(comment_only) %>%
  select(-comment_only) %>%
  group_by(author, author_name) %>%
  tidyr::nest() %>%
  purrr::pmap(function(author, author_name, data) {
      htmltools::tags$li(
        author_name, " (",
        make_link(
          glue::glue("@{author}"),
          glue::glue("https://github.com/{author}")
        ),"): ",
        make_link(paste0("#", data$issue), data$issue_url)
      )
  }) %>%
  htmltools::tags$ul()
```

### Download Data

The data about issue's author has been found using the GitHub V4 API. For each issue, we can get information about each comments, and its author. The data has been simplified

* One observation per author, per issue he contributed
* `comment_only` is `TRUE` if the user only commented in the thread and not created the issue. It is `FALSE` if the user is the author of the issue.
* `author_name` has been filled using GitHub author profile. Some author name are empty because not found in the GH account and not know by us yet... 

```{r}
glimpse(other_authors)
```

You can download this data in RDS if necessary

```{r}
xfun::embed_file("other_authors.Rds", text = "Download data as RDS")
```

</br>
or view it and download as CSV is next tab.

### See the Data 

```{r}
 DT::datatable(other_authors,
                escape = FALSE, 
                filter = "top",
               extensions = 'Buttons', 
               options = list(
                 dom = 'Bfrtip',
                 buttons = c('copy', 'csv')
               )
 )
```
